{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***********************************************************************************************\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from music21 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of music21**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0} <music21.harmony.ChordSymbol C>\n",
      "{1.0} <music21.harmony.ChordSymbol F>\n",
      "{2.0} <music21.harmony.ChordSymbol G>\n",
      "{3.0} <music21.harmony.ChordSymbol C>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'chord_progression.mid'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from music21 import stream, harmony, duration\n",
    "# Create a stream to hold the chords\n",
    "chord_stream = stream.Stream()\n",
    "\n",
    "# Define the chord progression and durations\n",
    "chord_names = ['C', 'F', 'G', 'C']\n",
    "chord_durations = [1, 1, 1, 1]  # Whole notes\n",
    "\n",
    "# Create and add chords to the stream\n",
    "for chord_name, dur in zip(chord_names, chord_durations):\n",
    "    chord = harmony.ChordSymbol(chord_name)\n",
    "    chord.duration = duration.Duration(dur)\n",
    "    chord_stream.append(chord)\n",
    "\n",
    "# Show the stream\n",
    "chord_stream.show('text')  # This will display the stream in a text-based format\n",
    "\n",
    "# To create a MIDI file:\n",
    "chord_stream.write('midi', fp='chord_progression.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agent Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Musical Key Definition:\\n\\nThe function starts by defining a simple musical key represented by the musical_key list. This key consists of chords like \\'C\\', \\'Dm\\', \\'Em\\', etc.\\nExtracting Last and Current Chords:\\n\\nIt extracts the last chosen chord from the state. The assumption is that the chord information is present in the last part of the state. The index of the most activated chord is found using np.argmax(state[0][-len(musical_key):]), and the actual chord is retrieved.\\nIt extracts the current chosen chord from the action using modulo (%) to ensure that the index is within the range of the musical key.\\nTransition Matrix Definition:\\n\\nA transition_matrix is defined. This matrix represents the transition probabilities between chords. Each row corresponds to a \"from\" chord, and each column corresponds to a \"to\" chord. The values in the matrix represent the probabilities of transitioning from one chord to another.\\nReward Calculation:\\n\\nThe reward is calculated based on the transition probability from the last chord to the current chord. The reward is a value between 0 and 1, indicating the likelihood of the chosen transition in the context of the defined musical theory.\\nReward Return:\\n\\nThe calculated reward is returned.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MusicComposerAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size  # Length of the chord sequence representing the state\n",
    "        self.action_size = action_size  # Number of possible actions (chords)\n",
    "        self.memory = []  # Memory for storing experiences\n",
    "        self.gamma = 0.95  # Discount rate for future rewards\n",
    "        self.epsilon = 1.0  # Exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.lstm_model = self._build_lstm_model()\n",
    "\n",
    "    def _build_lstm_model(self):\n",
    "        \"\"\"Builds an LSTM network to be used by the agent.\"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, input_shape=(self.state_size, self.action_size), return_sequences=True))\n",
    "        model.add(LSTM(50))\n",
    "        model.add(Dense(self.action_size, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        \"\"\"Chooses the next action (chord) based on the current state.\"\"\"\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.randint(self.action_size)  # Explore: choose a random action\n",
    "        action_probs = self.lstm_model.predict(state)  # Exploit: choose best action based on model\n",
    "        return np.argmax(action_probs[0])\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Stores an experience in memory.\"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        \"\"\"Trains the agent using a batch of past experiences.\"\"\"\n",
    "        minibatch = np.random.choice(self.memory, batch_size, replace=False)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma * np.amax(self.lstm_model.predict(next_state)[0]))\n",
    "            target_f = self.lstm_model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.lstm_model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def calculate_reward(self, state, action):\n",
    "        musical_key = ['C', 'Dm', 'Em', 'F', 'G', 'Am', 'Bdim']\n",
    "        chord_history_length = 4  # Number of previous chords to consider for context\n",
    "        reward = 0\n",
    "\n",
    "        # Extract the current and previous chords\n",
    "        current_chord_index = action % len(musical_key) # Determine the index of the current chord based on the agent's action.\n",
    "        current_chord = musical_key[current_chord_index] # Retrieve the current chord from the musical key using the index.\n",
    "        # Create a list of previously selected chords based on the current state.\n",
    "        previous_chords = [\n",
    "            musical_key[np.argmax(state[0][i:i + len(musical_key)])] # finds the index of the highest value in each segment, which corresponds to the selected chord in that part of the state.\n",
    "            for i in range(len(state[0]) - chord_history_length * len(musical_key), len(state[0]), len(musical_key))\n",
    "        ]\n",
    "\n",
    "        # Reward/Penalty for chord progression\n",
    "        if len(previous_chords) == chord_history_length:\n",
    "            # Reward cadences or common progressions\n",
    "            if previous_chords[-2:] == ['F', 'G'] and current_chord == 'C':  # IV-V-I progression\n",
    "                reward += 0.5\n",
    "\n",
    "        # Penalty for excessive repetition\n",
    "        if previous_chords.count(current_chord) > 2:  # Penalize if the same chord is repeated too often\n",
    "            reward -= 0.3\n",
    "\n",
    "        transition_matrix = [\n",
    "        [0.15, 0.1, 0.15, 0.2, 0.15, 0.1, 0],  #C\n",
    "        [0.15, 0.05, 0.1, 0.15, 0.18, 0.15, 0],  #Dm\n",
    "        [0.15, 0.1, 0.1, 0.18, 0.15, 0.15, 0.1],  #Em\n",
    "        [0.18, 0.1, 0.15, 0.15, 0.15, 0.15, 0.1],  #F\n",
    "        [0.18, 0.1, 0.1, 0.15, 0.15, 0.1, 0.1],  #G\n",
    "        [0.15, 0.15, 0.1, 0.15, 0.1, 0.1, 0],  #Am\n",
    "        [0.15, 0, 0.1, 0.1, 0.1, 0.05, 0]   #Bdim\n",
    "        ]\n",
    "\n",
    "        last_chord_index = np.argmax(state[0][-len(musical_key):])\n",
    "        immediate_transition_reward = transition_matrix[last_chord_index][current_chord_index]\n",
    "        reward += immediate_transition_reward\n",
    "\n",
    "        # Ensure the reward is non-negative\n",
    "        reward = max(reward, 0)\n",
    "\n",
    "        return reward\n",
    "\n",
    "\n",
    "    def train(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = np.random.choice(self.memory, batch_size, replace=False)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma * np.amax(self.lstm_model.predict(next_state)[0]))\n",
    "            target_f = self.lstm_model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.lstm_model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "'''Musical Key Definition:\n",
    "\n",
    "The function starts by defining a simple musical key represented by the musical_key list. This key consists of chords like 'C', 'Dm', 'Em', etc.\n",
    "Extracting Last and Current Chords:\n",
    "\n",
    "It extracts the last chosen chord from the state. The assumption is that the chord information is present in the last part of the state. The index of the most activated chord is found using np.argmax(state[0][-len(musical_key):]), and the actual chord is retrieved.\n",
    "It extracts the current chosen chord from the action using modulo (%) to ensure that the index is within the range of the musical key.\n",
    "Transition Matrix Definition:\n",
    "\n",
    "A transition_matrix is defined. This matrix represents the transition probabilities between chords. Each row corresponds to a \"from\" chord, and each column corresponds to a \"to\" chord. The values in the matrix represent the probabilities of transitioning from one chord to another.\n",
    "Reward Calculation:\n",
    "\n",
    "The reward is calculated based on the transition probability from the last chord to the current chord. The reward is a value between 0 and 1, indicating the likelihood of the chosen transition in the context of the defined musical theory.\n",
    "Reward Return:\n",
    "\n",
    "The calculated reward is returned.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chord: <music21.harmony.ChordSymbol Am>, Duration: 1\n"
     ]
    }
   ],
   "source": [
    "from music21 import harmony, duration\n",
    "\n",
    "def action_to_chord_duration(action_index):\n",
    "    # Define chords and durations\n",
    "    chords = ['C', 'Dm', 'Em', 'F', 'G', 'Am', 'Bdim', 'Cmaj7', 'Dm7', 'G7']\n",
    "    durations = [1]  # can use [0.25, 0.5, 1, 2] Representing quarter, half, whole, and double whole notes\n",
    "\n",
    "    num_chords = len(chords)\n",
    "    num_durations = len(durations)\n",
    "\n",
    "    # Calculate the chord index and duration index\n",
    "    chord_index = action_index % num_chords\n",
    "    duration_index = action_index // num_chords\n",
    "\n",
    "    chord_name = chords[chord_index]\n",
    "    dur = durations[duration_index]\n",
    "\n",
    "    # Create a chord symbol and set its duration\n",
    "    chord = harmony.ChordSymbol(chord_name)\n",
    "    chord.duration = duration.Duration(dur)\n",
    "\n",
    "    return chord, dur\n",
    "\n",
    "# Example usage\n",
    "action_index = 5  # Suppose the agent chose action index 5\n",
    "chord, dur = action_to_chord_duration(action_index)\n",
    "print(f\"Chord: {chord}, Duration: {dur}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sequence (indices): [4 2 3 0 5 1 4 0 4 2 8 1 7 6 1 7 8 2 4 2 0 4 1 0 3 4 2 7 9 0 5 2]\n",
      "Example sequence (chords): ['G', 'Em', 'F', 'C', 'Am', 'Dm', 'G', 'C', 'G', 'Em', 'Dm7', 'Dm', 'Cmaj7', 'Bdim', 'Dm', 'Cmaj7', 'Dm7', 'Em', 'G', 'Em', 'C', 'G', 'Dm', 'C', 'F', 'G', 'Em', 'Cmaj7', 'G7', 'C', 'Am', 'Em']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The dataset serves as a memory of past experiences,\\n allowing the agent to learn from its interactions with the environment. During training,\\n the agent explores the musical space, chooses chords, and receives rewards based on the defined reward function. The experiences\\n (state, action, reward) are stored in the dataset, and the agent uses this dataset to learn the patterns that lead to higher rewards.\\n\\n In the provided dataset, the first row is:\\n0,1,2,3,4\\n\\nThis represents a sequence of chord indices. The mapping of these indices to actual chord names would depend on the context of our application. For example,\\n if we have a predefined set of chords like ['C', 'Dm', 'Em', 'F', 'G', 'Am', 'Bdim', 'Cmaj7', 'Dm7', 'G7']\\n, then the sequence [0,1,2,3,4] would correspond to: C,Dm,Em,F,G\\n \""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chord mapping to indices\n",
    "chords = ['C', 'Dm', 'Em', 'F', 'G', 'Am', 'Bdim', 'Cmaj7', 'Dm7', 'G7']\n",
    "chord_to_index = {chord: i for i, chord in enumerate(chords)}\n",
    "\n",
    "# Generate sequences\n",
    "num_sequences = 10000\n",
    "sequence_length = 32\n",
    "dataset = []\n",
    "\n",
    "for _ in range(num_sequences):\n",
    "    sequence = []\n",
    "    for _ in range(sequence_length):\n",
    "        if not sequence or sequence[-1] == chord_to_index['C']:\n",
    "            # Start with C or follow C with F or G or Am\n",
    "            next_chord = np.random.choice([chord_to_index['F'], chord_to_index['G'], chord_to_index['Am']])\n",
    "        elif sequence[-1] == chord_to_index['F']:\n",
    "            # Follow F with G or C\n",
    "            next_chord = np.random.choice([chord_to_index['G'], chord_to_index['C']])\n",
    "        elif sequence[-1] == chord_to_index['G']:\n",
    "            # Follow G with C or Dm or Em\n",
    "            next_chord = np.random.choice([chord_to_index['C'], chord_to_index['Dm'], chord_to_index['Em']])\n",
    "        else:\n",
    "            # Randomly choose any chord as a fallback\n",
    "            next_chord = np.random.randint(len(chords))\n",
    "\n",
    "        sequence.append(next_chord)\n",
    "    dataset.append(sequence)\n",
    "\n",
    "# Convert to a format suitable for training\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "# Print the first sequence as an example\n",
    "print(\"Example sequence (indices):\", dataset[0])\n",
    "print(\"Example sequence (chords):\", [chords[i] for i in dataset[0]])\n",
    "\n",
    "'''The dataset serves as a memory of past experiences,\n",
    " allowing the agent to learn from its interactions with the environment. During training,\n",
    " the agent explores the musical space, chooses chords, and receives rewards based on the defined reward function. The experiences\n",
    " (state, action, reward) are stored in the dataset, and the agent uses this dataset to learn the patterns that lead to higher rewards.\n",
    "\n",
    " In the provided dataset, the first row is:\n",
    "0,1,2,3,4\n",
    "\n",
    "This represents a sequence of chord indices. The mapping of these indices to actual chord names would depend on the context of our application. For example,\n",
    " if we have a predefined set of chords like ['C', 'Dm', 'Em', 'F', 'G', 'Am', 'Bdim', 'Cmaj7', 'Dm7', 'G7']\n",
    ", then the sequence [0,1,2,3,4] would correspond to: C,Dm,Em,F,G\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 completed\n",
      "Epoch 2/100 completed\n",
      "Epoch 3/100 completed\n",
      "Epoch 4/100 completed\n",
      "Epoch 5/100 completed\n",
      "Epoch 6/100 completed\n",
      "Epoch 7/100 completed\n",
      "Epoch 8/100 completed\n",
      "Epoch 9/100 completed\n",
      "Epoch 10/100 completed\n",
      "Epoch 11/100 completed\n",
      "Epoch 12/100 completed\n",
      "Epoch 13/100 completed\n",
      "Epoch 14/100 completed\n",
      "Epoch 15/100 completed\n",
      "Epoch 16/100 completed\n",
      "Epoch 17/100 completed\n",
      "Epoch 18/100 completed\n",
      "Epoch 19/100 completed\n",
      "Epoch 20/100 completed\n",
      "Epoch 21/100 completed\n",
      "Epoch 22/100 completed\n",
      "Epoch 23/100 completed\n",
      "Epoch 24/100 completed\n",
      "Epoch 25/100 completed\n",
      "Epoch 26/100 completed\n",
      "Epoch 27/100 completed\n",
      "Epoch 28/100 completed\n",
      "Epoch 29/100 completed\n",
      "Epoch 30/100 completed\n",
      "Epoch 31/100 completed\n",
      "Epoch 32/100 completed\n",
      "Epoch 33/100 completed\n",
      "Epoch 34/100 completed\n",
      "Epoch 35/100 completed\n",
      "Epoch 36/100 completed\n",
      "Epoch 37/100 completed\n",
      "Epoch 38/100 completed\n",
      "Epoch 39/100 completed\n",
      "Epoch 40/100 completed\n",
      "Epoch 41/100 completed\n",
      "Epoch 42/100 completed\n",
      "Epoch 43/100 completed\n",
      "Epoch 44/100 completed\n",
      "Epoch 45/100 completed\n",
      "Epoch 46/100 completed\n",
      "Epoch 47/100 completed\n",
      "Epoch 48/100 completed\n",
      "Epoch 49/100 completed\n",
      "Epoch 50/100 completed\n",
      "Epoch 51/100 completed\n",
      "Epoch 52/100 completed\n",
      "Epoch 53/100 completed\n",
      "Epoch 54/100 completed\n",
      "Epoch 55/100 completed\n",
      "Epoch 56/100 completed\n",
      "Epoch 57/100 completed\n",
      "Epoch 58/100 completed\n",
      "Epoch 59/100 completed\n",
      "Epoch 60/100 completed\n",
      "Epoch 61/100 completed\n",
      "Epoch 62/100 completed\n",
      "Epoch 63/100 completed\n",
      "Epoch 64/100 completed\n",
      "Epoch 65/100 completed\n",
      "Epoch 66/100 completed\n",
      "Epoch 67/100 completed\n",
      "Epoch 68/100 completed\n",
      "Epoch 69/100 completed\n",
      "Epoch 70/100 completed\n",
      "Epoch 71/100 completed\n",
      "Epoch 72/100 completed\n",
      "Epoch 73/100 completed\n",
      "Epoch 74/100 completed\n",
      "Epoch 75/100 completed\n",
      "Epoch 76/100 completed\n",
      "Epoch 77/100 completed\n",
      "Epoch 78/100 completed\n",
      "Epoch 79/100 completed\n",
      "Epoch 80/100 completed\n",
      "Epoch 81/100 completed\n",
      "Epoch 82/100 completed\n",
      "Epoch 83/100 completed\n",
      "Epoch 84/100 completed\n",
      "Epoch 85/100 completed\n",
      "Epoch 86/100 completed\n",
      "Epoch 87/100 completed\n",
      "Epoch 88/100 completed\n",
      "Epoch 89/100 completed\n",
      "Epoch 90/100 completed\n",
      "Epoch 91/100 completed\n",
      "Epoch 92/100 completed\n",
      "Epoch 93/100 completed\n",
      "Epoch 94/100 completed\n",
      "Epoch 95/100 completed\n",
      "Epoch 96/100 completed\n",
      "Epoch 97/100 completed\n",
      "Epoch 98/100 completed\n",
      "Epoch 99/100 completed\n",
      "Epoch 100/100 completed\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Convert sequences to a format suitable for training\n",
    "def one_hot_encode(sequence, num_classes):\n",
    "    return to_categorical(sequence, num_classes=num_classes)\n",
    "\n",
    "encoded_dataset = [one_hot_encode(sequence, action_size) for sequence in dataset]\n",
    "\n",
    "# Parameters for the agent\n",
    "state_size = 32\n",
    "action_size = 10\n",
    "\n",
    "# Initialize the agent\n",
    "agent = MusicComposerAgent(state_size, action_size)\n",
    "\n",
    "# Training the agent\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "for epoch in range(num_epochs):\n",
    "    for sequence in encoded_dataset:\n",
    "        for i in range(0, len(sequence) - state_size):\n",
    "            state = sequence[i:i + state_size]\n",
    "            next_state = sequence[i + 1:i + state_size + 1]\n",
    "            action = np.argmax(sequence[i + state_size])\n",
    "            reward = agent.calculate_reward(state, action)\n",
    "            done = (i + state_size + 1 == len(sequence))\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "    if agent.epsilon > agent.epsilon_min:\n",
    "        agent.epsilon *= agent.epsilon_decay\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 472ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv261\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv261_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv261\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCM5g/y8ATVRyawAAA14A/wMAAOAAQM5gkDdaAJA7WgCQPlrOYIA3AACAOwAAgD4AAJAwWgCQNFoAkDdaAJA7Ws5ggDAAAIA0AACANwAAgDsAAJAvWgCQMloAkDVazmCALwAAgDIAAIA1AACQNFoAkDdaAJA7Ws5ggDQAAIA3AACAOwAAkDJaAJA1WgCQOVrOYIAyAACANQAAgDkAAJAwWgCQNFoAkDdazmCAMAAAgDQAAIA3AACQMloAkDVaAJA5Ws5ggDIAAIA1AACAOQAAkDBaAJA0WgCQN1oAkDtazmCAMAAAgDQAAIA3AACAOwAAkDVaAJA5WgCQPFrOYIA1AACAOQAAgDwAAJAwWgCQNFoAkDdazmCAMAAAgDQAAIA3AACQN1oAkDtaAJA+Ws5ggDcAAIA7AACAPgAAkDJaAJA1WgCQOVrOYIAyAACANQAAgDkAAJAwWgCQNFoAkDdazmCAMAAAgDQAAIA3AACQMFoAkDRaAJA3Ws5ggDAAAIA0AACANwAAkC1aAJAwWgCQNFrOYIAtAACAMAAAgDQAAJAtWgCQMFoAkDRazmCALQAAgDAAAIA0AACQNFoAkDdaAJA7Ws5ggDQAAIA3AACAOwAAkDBaAJA0WgCQN1oAkDtazmCAMAAAgDQAAIA3AACAOwAAkDBaAJA0WgCQN1oAkDtazmCAMAAAgDQAAIA3AACAOwAAkDJaAJA1WgCQOVrOYIAyAACANQAAgDkAAJAwWgCQNFoAkDdazmCAMAAAgDQAAIA3AACQMFoAkDRaAJA3WgCQO1rOYIAwAACANAAAgDcAAIA7AACQMloAkDVaAJA5Ws5ggDIAAIA1AACAOQAAkDBaAJA0WgCQN1rOYIAwAACANAAAgDcAAJAvWgCQMloAkDVazmCALwAAgDIAAIA1AACQL1oAkDJaAJA1Ws5ggC8AAIAyAACANQAAkDBaAJA0WgCQN1rOYIAwAACANAAAgDcAAJAwWgCQNFoAkDdazmCAMAAAgDQAAIA3AACQMloAkDVaAJA5Ws5ggDIAAIA1AACAOQAAkDBaAJA0WgCQN1rOYIAwAACANAAAgDcAAJAwWgCQNFoAkDdazmCAMAAAgDQAAIA3AACQMloAkDVaAJA5WgCQPFrOYIAyAACANQAAgDkAAIA8AM5g/y8A\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv261_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv261_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to generate a sequence of chords using the trained agent\n",
    "def generate_chords(agent, initial_state, desired_length, state_size, action_size):\n",
    "    generated_sequence = initial_state.copy()\n",
    "    for _ in range(desired_length):\n",
    "        if len(generated_sequence) < state_size:\n",
    "            current_state = np.zeros((state_size, action_size))  # Padding with zeros\n",
    "        else:\n",
    "            current_state = one_hot_encode(generated_sequence[-state_size:], action_size)\n",
    "\n",
    "        current_state_input = np.reshape(current_state, (1, state_size, action_size))\n",
    "        next_action = agent.choose_action(current_state_input)\n",
    "        generated_sequence.append(next_action)\n",
    "    \n",
    "    return generated_sequence\n",
    "\n",
    "# Generate a new song\n",
    "desired_length = 32  # Length of the song (number of chords)\n",
    "initial_state = []   # Starting with an empty sequence\n",
    "generated_chords = generate_chords(agent, initial_state, desired_length, state_size, action_size)\n",
    "\n",
    "# Convert the generated sequence to music21 stream\n",
    "generated_composition = stream.Stream()\n",
    "for action_index in generated_chords:\n",
    "    chord_symbol, chord_duration = action_to_chord_duration(action_index)\n",
    "    generated_composition.append(chord_symbol)\n",
    "\n",
    "# Show or play the generated composition\n",
    "generated_composition.show('midi')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
